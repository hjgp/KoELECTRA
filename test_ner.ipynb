{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b09813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "from transformers import ElectraForTokenClassification, ElectraTokenizer\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95058534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(x, path) :\n",
    "    model = ElectraForTokenClassification.from_pretrained(path)\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-small-v3-discriminator\")\n",
    "    \n",
    "    emojis = ''.join(emoji.UNICODE_EMOJI.keys())  \n",
    "    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n",
    "    url_pattern = re.compile(\n",
    "        r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "    )\n",
    "    processed = pattern.sub(' ', x)\n",
    "    processed = url_pattern.sub(' ', processed)\n",
    "    processed = processed.strip()\n",
    "    processed = repeat_normalize(processed, num_repeats=2)\n",
    "\n",
    "    tokenized = tokenizer(processed, return_tensors='pt')\n",
    "\n",
    "    output = model(tokenized.input_ids, tokenized.attention_mask)\n",
    "    return nn.functional.softmax(output.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc20eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/hjgp/research/NH_intern/reviews_namu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3139f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = infer(train_df['content'][:10][0], '/home/hjgp/research/KoELECTRA/finetune/ckpt/koelectra-small-v3-naver-ner-ckpt/checkpoint-50000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3c3407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9935e-01, 5.0352e-05, 1.4876e-06,  ..., 1.0579e-07,\n",
       "          2.6345e-04, 7.2289e-06],\n",
       "         [9.9752e-01, 5.0367e-05, 6.2938e-07,  ..., 1.1593e-08,\n",
       "          5.3163e-05, 6.3159e-07],\n",
       "         [9.9986e-01, 7.8302e-06, 1.9466e-07,  ..., 9.2359e-09,\n",
       "          4.6170e-05, 1.8254e-06],\n",
       "         ...,\n",
       "         [5.5322e-02, 1.4732e-04, 6.8648e-04,  ..., 1.2758e-03,\n",
       "          2.7526e-02, 8.6371e-01],\n",
       "         [3.2001e-02, 2.1407e-04, 2.1732e-04,  ..., 1.0253e-03,\n",
       "          4.6697e-03, 2.0771e-01],\n",
       "         [9.9936e-01, 4.9323e-05, 1.4574e-06,  ..., 1.0294e-07,\n",
       "          2.5568e-04, 7.0713e-06]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dffae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertConfig,\n",
    "    DistilBertConfig,\n",
    "    ElectraConfig,\n",
    "    XLMRobertaConfig,\n",
    "    ElectraTokenizer,\n",
    "    XLMRobertaTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    DistilBertForSequenceClassification,\n",
    "    ElectraForSequenceClassification,\n",
    "    XLMRobertaForSequenceClassification,\n",
    "    BertForTokenClassification,\n",
    "    DistilBertForTokenClassification,\n",
    "    ElectraForTokenClassification,\n",
    "    XLMRobertaForTokenClassification,\n",
    "    BertForQuestionAnswering,\n",
    "    DistilBertForQuestionAnswering,\n",
    "    ElectraForQuestionAnswering,\n",
    "    XLMRobertaForQuestionAnswering,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
